{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EA run comparisons 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all experiment data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (6659, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>island</th>\n",
       "      <th>cvMseMean</th>\n",
       "      <th>cvMseStd</th>\n",
       "      <th>cvSmapeMean</th>\n",
       "      <th>cvSmapeStd</th>\n",
       "      <th>holdoutRmse</th>\n",
       "      <th>holdoutSmape</th>\n",
       "      <th>holdoutMape</th>\n",
       "      <th>holdoutMse</th>\n",
       "      <th>holdoutIoa</th>\n",
       "      <th>full_parameters</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>worker</th>\n",
       "      <th>experiment</th>\n",
       "      <th>cvSmapeMeanAccuracy</th>\n",
       "      <th>holdoutSmapeAccuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1563747100</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>483.107126</td>\n",
       "      <td>44.939292</td>\n",
       "      <td>13.379213</td>\n",
       "      <td>0.775774</td>\n",
       "      <td>29.238121</td>\n",
       "      <td>14.629771</td>\n",
       "      <td>inf</td>\n",
       "      <td>854.867735</td>\n",
       "      <td>0.650298</td>\n",
       "      <td>[31.0, 600.0, 4.0, 512.0, 512.0, 64.0, 0.25, 0...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...</td>\n",
       "      <td>86.620787</td>\n",
       "      <td>85.370229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563747702</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>482.562458</td>\n",
       "      <td>45.272642</td>\n",
       "      <td>13.336051</td>\n",
       "      <td>0.810653</td>\n",
       "      <td>29.224129</td>\n",
       "      <td>14.647241</td>\n",
       "      <td>inf</td>\n",
       "      <td>854.049699</td>\n",
       "      <td>0.651877</td>\n",
       "      <td>[31.0, 600.0, 4.0, 512.0, 512.0, 64.0, 0.25, 0...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...</td>\n",
       "      <td>86.663949</td>\n",
       "      <td>85.352759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563748389</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>172.173384</td>\n",
       "      <td>60.361243</td>\n",
       "      <td>8.614378</td>\n",
       "      <td>1.554654</td>\n",
       "      <td>24.084382</td>\n",
       "      <td>13.177726</td>\n",
       "      <td>inf</td>\n",
       "      <td>580.057433</td>\n",
       "      <td>0.864540</td>\n",
       "      <td>[24.713216520933585, 499.9543694094754, 3.1263...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...</td>\n",
       "      <td>91.385622</td>\n",
       "      <td>86.822274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563749134</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>172.674499</td>\n",
       "      <td>58.940749</td>\n",
       "      <td>8.665994</td>\n",
       "      <td>1.556883</td>\n",
       "      <td>21.596358</td>\n",
       "      <td>12.478397</td>\n",
       "      <td>inf</td>\n",
       "      <td>466.402700</td>\n",
       "      <td>0.882106</td>\n",
       "      <td>[24.713216530933586, 499.9543694094754, 3.1263...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...</td>\n",
       "      <td>91.334006</td>\n",
       "      <td>87.521603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563750788</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>206.050960</td>\n",
       "      <td>57.548934</td>\n",
       "      <td>9.374015</td>\n",
       "      <td>1.505576</td>\n",
       "      <td>18.609927</td>\n",
       "      <td>10.336197</td>\n",
       "      <td>inf</td>\n",
       "      <td>346.329389</td>\n",
       "      <td>0.897852</td>\n",
       "      <td>[24.713216520933585, 499.9543694194754, 3.1263...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...</td>\n",
       "      <td>90.625985</td>\n",
       "      <td>89.663803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            iteration  island   cvMseMean   cvMseStd  cvSmapeMean  cvSmapeStd  \\\n",
       "datetime                                                                        \n",
       "1563747100         52       1  483.107126  44.939292    13.379213    0.775774   \n",
       "1563747702         53       1  482.562458  45.272642    13.336051    0.810653   \n",
       "1563748389         54       1  172.173384  60.361243     8.614378    1.554654   \n",
       "1563749134         55       1  172.674499  58.940749     8.665994    1.556883   \n",
       "1563750788         56       1  206.050960  57.548934     9.374015    1.505576   \n",
       "\n",
       "            holdoutRmse  holdoutSmape  holdoutMape  holdoutMse  holdoutIoa  \\\n",
       "datetime                                                                     \n",
       "1563747100    29.238121     14.629771          inf  854.867735    0.650298   \n",
       "1563747702    29.224129     14.647241          inf  854.049699    0.651877   \n",
       "1563748389    24.084382     13.177726          inf  580.057433    0.864540   \n",
       "1563749134    21.596358     12.478397          inf  466.402700    0.882106   \n",
       "1563750788    18.609927     10.336197          inf  346.329389    0.897852   \n",
       "\n",
       "                                              full_parameters optimizer  \\\n",
       "datetime                                                                  \n",
       "1563747100  [31.0, 600.0, 4.0, 512.0, 512.0, 64.0, 0.25, 0...        ls   \n",
       "1563747702  [31.0, 600.0, 4.0, 512.0, 512.0, 64.0, 0.25, 0...        ls   \n",
       "1563748389  [24.713216520933585, 499.9543694094754, 3.1263...        ls   \n",
       "1563749134  [24.713216530933586, 499.9543694094754, 3.1263...        ls   \n",
       "1563750788  [24.713216520933585, 499.9543694194754, 3.1263...        ls   \n",
       "\n",
       "           worker                                         experiment  \\\n",
       "datetime                                                               \n",
       "1563747100    TX2  18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...   \n",
       "1563747702    TX2  18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...   \n",
       "1563748389    TX2  18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...   \n",
       "1563749134    TX2  18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...   \n",
       "1563750788    TX2  18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-...   \n",
       "\n",
       "            cvSmapeMeanAccuracy  holdoutSmapeAccuracy  \n",
       "datetime                                               \n",
       "1563747100            86.620787             85.370229  \n",
       "1563747702            86.663949             85.352759  \n",
       "1563748389            91.385622             86.822274  \n",
       "1563749134            91.334006             87.521603  \n",
       "1563750788            90.625985             89.663803  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "run_directory_prefix = \"../models/NarxModelSearch/runs/\"\n",
    "file_name_pattern = \"*Runs.csv\"\n",
    "columns = [\"datetime\", \"iteration\", \"island\", \"cvMseMean\", \"cvMseStd\", \"cvSmapeMean\", \"cvSmapeStd\", \"holdoutRmse\", \"holdoutSmape\", \"holdoutMape\", \"holdoutMse\", \"holdoutIoa\", \"full_parameters\"]\n",
    "\n",
    "experiment_directories = [\"18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18Islands20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18Islands5AgentsO3_1994-2018_16_stations_calendar\",\n",
    "                          \"18CellularAutomata3DGrid3x3x3_5AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "                          \"18Islands20AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "                          \"18Islands5AgentsPM10_1994-2018_16_stations_calendar\"\n",
    "                         ]\n",
    "\n",
    "run_directories = []\n",
    "for experiment_directory in experiment_directories:\n",
    "    new_run_directory = run_directory_prefix + experiment_directory + \"/\"\n",
    "#     print(\"new_run_directory:\", new_run_directory)\n",
    "    run_directories.append(new_run_directory)\n",
    "\n",
    "worker_directories = [\"local\", \"TX2\"]\n",
    "\n",
    "# print(run_directories)\n",
    "\n",
    "dirs_list = []\n",
    "for run_directory in run_directories:\n",
    "    dirs_list.append(os.listdir(run_directory))\n",
    "#     print(\"dirs:\", os.listdir(run_directory))\n",
    "    \n",
    "for dirs in dirs_list:\n",
    "    for item in dirs:\n",
    "        if item not in worker_directories:\n",
    "            sub_items = os.listdir(run_directories[0] + item)\n",
    "            for sub_item in sub_items:\n",
    "                sub_path = item +\"/\" + sub_item\n",
    "#                 print(\"sub_path:\", item +\"/\" + sub_item)\n",
    "                worker_directories.append(sub_path)\n",
    "            \n",
    "# print(\"worker_directories:\", worker_directories)\n",
    "\n",
    "paths = []\n",
    "for run_directory in run_directories:\n",
    "    for worker_directory in worker_directories:\n",
    "        experiment = \"\"\n",
    "        if run_directory.startswith(run_directory_prefix):\n",
    "            experiment = run_directory[len(run_directory_prefix):-1]\n",
    "#         print(\"experiment:\", experiment)\n",
    "        paths.append((run_directory + worker_directory + \"/logs/\", worker_directory, experiment))\n",
    "\n",
    "# print(len(paths))\n",
    "    \n",
    "frames = []\n",
    "for path in paths:\n",
    "    for csv_file_path in glob.glob(path[0] + file_name_pattern):\n",
    "#         print(\"csv_file_path:\", csv_file_path)\n",
    "#         print(\"csv_file     :\", csv_file)\n",
    "        df = pd.read_csv(csv_file_path, names=columns, engine=\"python\", index_col=\"datetime\", parse_dates=True)\n",
    "    \n",
    "        if \"EC2\" in path[1]:  # EC2 -> + 1 hour (Ireland)\n",
    "            df.index = df.index + 3600\n",
    "        if \"TX2\" in path[1]:  # TX2 -> + 2 hours (UTC)        \n",
    "            df.index = df.index + 3600 * 2\n",
    "    \n",
    "        df.sort_index(inplace=True)\n",
    "        df[\"optimizer\"] = str(re.search('(.{1,6})Runs.csv', os.path.basename(csv_file_path)).group(1))\n",
    "        df[\"worker\"] = path[1]\n",
    "        df[\"experiment\"] = path[2]\n",
    "        df[\"cvSmapeMeanAccuracy\"] = 100 - df[\"cvSmapeMean\"]\n",
    "        df[\"holdoutSmapeAccuracy\"] = 100 - df[\"holdoutSmape\"]        \n",
    "#         print(\"df.shape\", df.shape)\n",
    "        frames.append(df)\n",
    "#         break\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(\"df.shape:\", df.shape)\n",
    "df.tail()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'holdoutSmapeAccuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4380\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4381\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4382\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-365af2cc7e5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"optimizer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mdict_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[0mdict_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4387\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4390\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4373\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4375\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4376\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'holdoutSmapeAccuracy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variables = [\n",
    "#     \"cvSmapeMeanAccuracy\", \n",
    "#     \"holdoutMse\",\n",
    "    \"holdoutSmapeAccuracy\",\n",
    "#     \"holdoutIoa\"\n",
    "]\n",
    "figure_size = [10, 6]\n",
    "remove_outliers = False\n",
    "outlier_std = 3\n",
    "minimizing = False\n",
    "\n",
    "def getMinimizingMaximizingArray(k, minimizing=True):\n",
    "    minsArray = []\n",
    "    minValue = k[0]\n",
    "    for value in np.array(k):\n",
    "        if minimizing:\n",
    "            if value < minValue:\n",
    "                minValue = value\n",
    "        else:\n",
    "            if value > minValue:\n",
    "                minValue = value\n",
    "        minsArray.append(minValue)    \n",
    "    return np.array(minsArray)\n",
    "    \n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "for current_experiment in experiment_directories:\n",
    "    \n",
    "    legends = []\n",
    "    for variable in variables:    \n",
    "       \n",
    "        df2 = df.loc[df[\"experiment\"] == current_experiment]        \n",
    "#         df2 = df2.loc[df2[\"optimizer\"] != \"ls\"]\n",
    "        \n",
    "        df2 = df2.drop_duplicates()\n",
    "        df2.sort_index(inplace=True)\n",
    "    \n",
    "        if remove_outliers:\n",
    "            df2 = df2[~(np.abs(df2[variable] - df2[variable].mean()) > (outlier_std * df2[variable].std()))]\n",
    "    \n",
    "        dict_points = {}        \n",
    "        for optimizer in df2[\"optimizer\"].unique():\n",
    "            dict_points[optimizer + \"_y\"] = []\n",
    "            dict_points[optimizer + \"_x\"] = []\n",
    "        i = 0\n",
    "        for index, row in df2.iterrows():\n",
    "            optimizer = row[\"optimizer\"]\n",
    "            dict_points[optimizer + \"_y\"].append(row[variable])\n",
    "            dict_points[optimizer + \"_x\"].append(i)            \n",
    "            i += 1\n",
    "    \n",
    "        x = np.array(range(0, len(df2[variable])))\n",
    "        y = df2[variable].values \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=figure_size)\n",
    "        ax.set_ylabel(\"100 - SMAPE%\")\n",
    "        ax.set_xlabel('# Fitness Evaluations')\n",
    "       \n",
    "#         z2 = np.polyfit(x, y, 2) \n",
    "#         trendpoly2d = np.poly1d(z2)\n",
    "#         ax.plot(x, trendpoly2d(x) , 'r--')\n",
    "#         legends.append(\"trend 2 degree polynomial\")\n",
    "        \n",
    "#         z12 = np.polyfit(x, y, 12) \n",
    "#         trendpoly12d = np.poly1d(z12)\n",
    "#         ax.plot(x, trendpoly12d(x) , 'c--')\n",
    "#         legends.append(\"trend 12 degree polynomial\")\n",
    "\n",
    "        # Scatter plot all data points based on method    \n",
    "        i = 0\n",
    "        styles = [\"x\", \".\", \"^\", \"+\", \"v\", \"1\", \"*\"]\n",
    "        for optimizer in df2[\"optimizer\"].unique():\n",
    "            ax.plot(dict_points[optimizer + \"_x\"], dict_points[optimizer + \"_y\"], styles[i]);\n",
    "#             legends.append(optimizer)\n",
    "            i += 1\n",
    "        legends = legends + [\"Bayesian Optimization (BO)\", \"Random (uniform) search (Rand)\", \"Differential Evolution (DE)\", \"Particle Swarm Optimization (PSO)\", \"Genetic Algorithm (GA)\", \"Local Search (LS)\"]\n",
    "\n",
    "        # Linear regression trend\n",
    "        z = np.polyfit(x, y, 1) \n",
    "        trendpoly1d = np.poly1d(z)\n",
    "#         print(\"trendpoly1d: \", trendpoly1d)\n",
    "        ax.plot(x, trendpoly1d(x) , 'k--')\n",
    "        legends.append(\"trend: {:.3f}*x + {:.3f}\".format(z[0], z[1]))        \n",
    "       \n",
    "        best_method = df2[\"optimizer\"].loc[df2[variable].idxmin()].upper()\n",
    "        ax.set_title('Island Transpeciation - PM10 test accuracy (median: {:.2f}% +/- {:.2f}%, worst: {:.2f}%, best: {:.2f}%)'\n",
    "                     .format(df2[variable].median(), df2[variable].mad(), df2[variable].min(), df2[variable].max()))\n",
    "                \n",
    "        ax.plot(x, getMinimizingMaximizingArray(df2[variable].values, minimizing), \"b-\");\n",
    "#         legends.append(\"minimizing \" + variable)\n",
    "        legends.append(\"Best model\")\n",
    "\n",
    "        ax.legend(legends)\n",
    "        \n",
    "        ax.grid(True)                         \n",
    "        fig.savefig(\"{}.svg\".format(current_experiment))    \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'holdoutSmapeAccuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4380\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4381\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4382\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-05e0e4bd764d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"optimizer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mdict_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mdict_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4387\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4390\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflowLast\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4373\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 4375\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   4376\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4377\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'holdoutSmapeAccuracy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "variables = [\n",
    "#     \"cvSmapeMeanAccuracy\", \n",
    "#     \"holdoutMse\",\n",
    "    \"holdoutSmapeAccuracy\",\n",
    "#     \"holdoutIoa\"\n",
    "]\n",
    "figure_size = [10, 8]\n",
    "remove_outliers = False\n",
    "outlier_std = 2\n",
    "minimizing = False\n",
    "\n",
    "def getMinimizingMaximizingArray(k, minimizing=True):\n",
    "    minsArray = []\n",
    "    minValue = k[0]\n",
    "    for value in np.array(k):\n",
    "        if minimizing:\n",
    "            if value < minValue:\n",
    "                minValue = value\n",
    "        else:\n",
    "            if value > minValue:\n",
    "                minValue = value\n",
    "        minsArray.append(minValue)    \n",
    "    return np.array(minsArray)\n",
    "    \n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "for current_experiment in experiment_directories:\n",
    "    \n",
    "    legends = []\n",
    "    for variable in variables:    \n",
    "       \n",
    "        df2 = df.loc[df[\"experiment\"] == current_experiment]\n",
    "        \n",
    "#         df2 = df2.loc[df2[\"optimizer\"] != \"ls\"]\n",
    "        \n",
    "        df2 = df2.drop_duplicates()\n",
    "        df2.sort_index(inplace=True)\n",
    "    \n",
    "        if remove_outliers:\n",
    "            df2 = df2[~(np.abs(df2[variable] - df2[variable].mean()) > (outlier_std * df2[variable].std()))]\n",
    "    \n",
    "        dict_points = {}        \n",
    "        for optimizer in df2[\"optimizer\"].unique():\n",
    "            dict_points[optimizer + \"_y\"] = []\n",
    "            dict_points[optimizer + \"_x\"] = []\n",
    "        i = 0\n",
    "        for index, row in df2.iterrows():\n",
    "            optimizer = row[\"optimizer\"]\n",
    "            dict_points[optimizer + \"_y\"].append(row[variable])\n",
    "            dict_points[optimizer + \"_x\"].append(i)            \n",
    "            i += 1\n",
    "    \n",
    "        x = np.array(range(0, len(df2[variable])))\n",
    "        y = df2[variable].values \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 1, figsize=figure_size)\n",
    "        ax.set_ylabel(variable)\n",
    "        ax.set_xlabel('# Fitness Evaluations')\n",
    "\n",
    "        # Linear regression trend\n",
    "        z = np.polyfit(x, y, 1) \n",
    "        trendpoly1d = np.poly1d(z)\n",
    "#         print(\"trendpoly1d: \", trendpoly1d)\n",
    "        ax.plot(x, trendpoly1d(x) , 'k--')\n",
    "        legends.append(\"trend \" + variable + \": {:.3f}*x + {:.3f}\".format(z[0], z[1]))\n",
    "        \n",
    "        z2 = np.polyfit(x, y, 2) \n",
    "        trendpoly2d = np.poly1d(z2)\n",
    "        ax.plot(x, trendpoly2d(x) , 'r--')\n",
    "        legends.append(\"trend 2 degree polynomial\")\n",
    "        \n",
    "        z12 = np.polyfit(x, y, 12) \n",
    "        trendpoly12d = np.poly1d(z12)\n",
    "        ax.plot(x, trendpoly12d(x) , 'c--')\n",
    "        legends.append(\"trend 12 degree polynomial\")\n",
    "                \n",
    "        # Scatter plot all data points based on method    \n",
    "        i = 0\n",
    "        styles = [\"x\", \".\", \"^\", \"+\", \"v\", \"1\", \"*\"]\n",
    "        for optimizer in df2[\"optimizer\"].unique():\n",
    "            ax.plot(dict_points[optimizer + \"_x\"], dict_points[optimizer + \"_y\"], styles[i]);\n",
    "            legends.append(optimizer)\n",
    "            i += 1\n",
    "\n",
    "        ax.plot(x, getMinimizingMaximizingArray(df2[variable].values, minimizing), \"b-\");\n",
    "        legends.append(\"minimizing \" + variable)\n",
    "        \n",
    "        ax.legend(legends)\n",
    "        best_method = df2[\"optimizer\"].loc[df2[variable].idxmin()]\n",
    "        ax.set_title('{} (evals: {}, min: {:.2f}, max: {:.2f}, median: {:.2f} +/- {:.2f}, mean: {:.2f} +/- {:.2f}, best: {}) - Experiment: {}'\n",
    "                     .format(variable, len(df2[variable]), df2[variable].min(), df2[variable].max(), df2[variable].median(), df2[variable].mad(), \n",
    "                             df2[variable].mean(), df2[variable].std(), best_method, current_experiment))\n",
    "        ax.grid(True) \n",
    "    \n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker execution times: Bar chart with error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def flatten(seq, container=None):\n",
    "    if container is None:\n",
    "        container = []\n",
    "    for s in seq:\n",
    "        try:\n",
    "            iter(s)  # check if it's iterable\n",
    "        except TypeError:\n",
    "            container.append(s)\n",
    "        else:\n",
    "            flatten(s, container)\n",
    "    return container\n",
    "\n",
    "workers = df[\"worker\"].unique()\n",
    "\n",
    "means = []\n",
    "samples = 0\n",
    "outlier_std = 3\n",
    "for current_worker in workers:\n",
    "    experiment_means = []\n",
    "    for current_experiment in experiment_directories:\n",
    "        df_worker = df.loc[df[\"experiment\"] == current_experiment]\n",
    "        df_worker = df_worker.loc[df_worker[\"worker\"] == current_worker]\n",
    "        df_worker = df_worker.drop_duplicates()\n",
    "        df_worker = df_worker.dropna()\n",
    "        df_worker.sort_index(inplace=True)\n",
    "        df_worker['datetimestamp'] = df_worker.index                \n",
    "        df_worker = df_worker[~(np.abs(df_worker[\"datetimestamp\"] - df_worker[\"datetimestamp\"].mean()) > (outlier_std * df_worker[\"datetimestamp\"].std()))]        \n",
    "        diff = df_worker[\"datetimestamp\"].diff().dropna()\n",
    "        mean = diff.mean(skipna=True)\n",
    "        if \"P100\" in current_worker or \"4xV100\" in current_worker:\n",
    "            mean *= 4        \n",
    "        if mean is not None and not math.isnan(mean):\n",
    "            samples += diff.size\n",
    "            experiment_means.append(mean / 60.0)\n",
    "    means.append(experiment_means)\n",
    "\n",
    "# Plot\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 14))\n",
    "workers = list(workers)\n",
    "fourV100 = workers.index('EC2/4xV100a')\n",
    "oneV100 = workers.index('EC2/1xV100')\n",
    "means[fourV100].append(means[oneV100][0])\n",
    "del means[oneV100]\n",
    "\n",
    "all_data = means\n",
    "labels = []\n",
    "for x, y in zip(['Tesla P100', 'GTX 970 & 1070Ti', 'Tesla V100', 'Jetson TX2'], [np.mean(x) for x in all_data]):\n",
    "    labels.append(\"{}\\n({:.2f} mins/model)\".format(x, y))\n",
    "\n",
    "axes[0].violinplot(all_data, showmeans=False, showmedians=True)\n",
    "axes[0].set_title('Violin plot - RNN (4 layers) training times vs GPU ({} samples, 99.73% CI)'.format(samples))\n",
    "axes[1].boxplot(all_data)\n",
    "axes[1].set_title('Box plot - RNN (4 layers) training times vs GPU ({} samples, 99.73% CI)'.format(samples))\n",
    "for ax in axes:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xticks([y+1 for y in range(len(all_data))])\n",
    "    ax.set_xlabel('GPU Workers')\n",
    "    ax.set_ylabel('Time (minutes)')\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "         xticklabels=labels)\n",
    "plt.savefig(\"rnnTrainingTimes.svg\")\n",
    "plt.savefig(\"rnnTrainingTimes.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "models_per_hour = []\n",
    "models_per_hour_std = []\n",
    "for gpu_worker in all_data:\n",
    "    models_per_hour.append(np.mean(60.0 / np.array(gpu_worker)))\n",
    "    models_per_hour_std.append(np.std(60.0 / np.array(gpu_worker)))\n",
    "prices = [5281, (136 + 369) / 2.0, 6865, 352]\n",
    "price_per_model_hour = np.array(prices) / np.array(models_per_hour)\n",
    "\n",
    "price_per_model_hour_std = price_per_model_hour * (np.array(models_per_hour_std) / np.array(models_per_hour))\n",
    "print(\"price_per_model_hour_std\", price_per_model_hour_std)\n",
    "\n",
    "gpu_workers = ['Tesla P100', 'GTX 970 & 1070Ti', 'Tesla V100', 'Jetson TX2']\n",
    "price_per_model_hour = [x for y,x in sorted(zip(gpu_workers, price_per_model_hour))]\n",
    "gpu_workers = [y for y,x in sorted(zip(gpu_workers, price_per_model_hour))]\n",
    "\n",
    "price_per_model_hour_std = [26.98099847, 64.96931466, 495.39481663,  110.15980803]  # TODO: hardcoded\n",
    "\n",
    "x = np.arange(4)\n",
    "def millions(x, pos):\n",
    "    return '{:.0f} €'.format(x)\n",
    "\n",
    "formatter = FuncFormatter(millions)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "plt.barh(x, price_per_model_hour, xerr=price_per_model_hour_std)\n",
    "# plt.barh(x, price_per_model_hour)\n",
    "ax.set_title('Cost per model-hour - RNN (4 layers) vs GPU ({} samples 99.73% CI)'.format(samples))\n",
    "ax.set_ylabel('GPU Workers')\n",
    "ax.set_xlabel('Price (€)')\n",
    "plt.yticks(x, gpu_workers)\n",
    "for i, v in enumerate(price_per_model_hour):\n",
    "    ax.text(v + 4, i + 0.1, str(round(v, 1)) + \"€ +/- {:.1f}€ per model-hour\".format(price_per_model_hour_std[i]) , color='blue', fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All models structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "run_directory_prefix = \"../models/NarxModelSearch/runs/\"\n",
    "file_name_pattern = \"*Runs.csv\"\n",
    "columns = [\"datetime\", \"iteration\", \"island\", \"cvMseMean\", \"cvMseStd\", \"cvSmapeMean\", \"cvSmapeStd\", \"holdoutRmse\", \"holdoutSmape\", \"holdoutMape\", \"holdoutMse\", \"holdoutIoa\", \"full_parameters\"]\n",
    "\n",
    "experiment_directories = [\"18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18Islands20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18Islands5AgentsO3_1994-2018_16_stations_calendar\",\n",
    "                          \"18CellularAutomata3DGrid3x3x3_5AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "                          \"18Islands20AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "                          \"18Islands5AgentsPM10_1994-2018_16_stations_calendar\"\n",
    "                         ]\n",
    "\n",
    "run_directories = []\n",
    "for experiment_directory in experiment_directories:\n",
    "    new_run_directory = run_directory_prefix + experiment_directory + \"/\"\n",
    "#     print(\"new_run_directory:\", new_run_directory)\n",
    "    run_directories.append(new_run_directory)\n",
    "\n",
    "worker_directories = [\"local\", \"TX2\"]\n",
    "\n",
    "# print(run_directories)\n",
    "\n",
    "dirs_list = []\n",
    "for run_directory in run_directories:\n",
    "    dirs_list.append(os.listdir(run_directory))\n",
    "#     print(\"dirs:\", os.listdir(run_directory))\n",
    "    \n",
    "for dirs in dirs_list:\n",
    "    for item in dirs:\n",
    "        if item not in worker_directories:\n",
    "            sub_items = os.listdir(run_directories[0] + item)\n",
    "            for sub_item in sub_items:\n",
    "                sub_path = item +\"/\" + sub_item\n",
    "#                 print(\"sub_path:\", item +\"/\" + sub_item)\n",
    "                worker_directories.append(sub_path)\n",
    "            \n",
    "# print(\"worker_directories:\", worker_directories)\n",
    "\n",
    "paths = []\n",
    "for run_directory in run_directories:\n",
    "    for worker_directory in worker_directories:\n",
    "        experiment = \"\"\n",
    "        if run_directory.startswith(run_directory_prefix):\n",
    "            experiment = run_directory[len(run_directory_prefix):-1]\n",
    "#         print(\"experiment:\", experiment)\n",
    "        paths.append((run_directory + worker_directory + \"/logs/\", worker_directory, experiment))\n",
    "\n",
    "# print(len(paths))\n",
    "    \n",
    "frames = []\n",
    "for path in paths:\n",
    "    for csv_file_path in glob.glob(path[0] + file_name_pattern):\n",
    "#         print(\"csv_file_path:\", csv_file_path)\n",
    "#         print(\"csv_file     :\", csv_file)\n",
    "        df = pd.read_csv(csv_file_path, names=columns, engine=\"python\", index_col=\"datetime\", parse_dates=True)\n",
    "    \n",
    "        if \"EC2\" in path[1]:  # EC2 -> + 1 hour (Ireland)\n",
    "            df.index = df.index + 3600\n",
    "        if \"TX2\" in path[1]:  # TX2 -> + 2 hours (UTC)        \n",
    "            df.index = df.index + 3600 * 2\n",
    "    \n",
    "        df.sort_index(inplace=True)\n",
    "        df[\"optimizer\"] = str(re.search('(.{1,6})Runs.csv', os.path.basename(csv_file_path)).group(1))\n",
    "        df[\"worker\"] = path[1]\n",
    "        df[\"experiment\"] = path[2]\n",
    "        df[\"cvSmapeMeanAccuracy\"] = 100 - df[\"cvSmapeMean\"]\n",
    "        df[\"holdoutSmapeAccuracy\"] = 100 - df[\"holdoutSmape\"]\n",
    "        \n",
    "        full_parameters = []\n",
    "        for params in df[\"full_parameters\"].tolist():\n",
    "#             print(params)\n",
    "            full_parameters.append([float(z) for z in params.replace('[', '').replace(']', '').split(\", \")])\n",
    "\n",
    "        df[\"full_parameters\"] = full_parameters        \n",
    "        a = [\"batch_size\",\n",
    "            \"epoch_size\",\n",
    "            \"optimizer\",\n",
    "            \"units1\",\n",
    "            \"units2\",\n",
    "            \"units3\",\n",
    "            \"dropout1\",\n",
    "            \"dropout2\",\n",
    "            \"dropout3\",\n",
    "            \"recurrent_dropout1\",\n",
    "            \"recurrent_dropout2\",\n",
    "            \"recurrent_dropout3\",\n",
    "            \"gaussian_noise_std1\",\n",
    "            \"gaussian_noise_std2\",\n",
    "            \"gaussian_noise_std3\",\n",
    "            \"batch_normalization1\",\n",
    "            \"batch_normalization2\",\n",
    "            \"batch_normalization3\",\n",
    "            \"gaussian_noise1\",\n",
    "            \"gaussian_noise2\",\n",
    "            \"gaussian_noise3\",\n",
    "            \"layer_type1\",\n",
    "            \"layer_type2\",\n",
    "            \"layer_type3\",\n",
    "            \"layer_initializer1\",\n",
    "            \"layer_initializer2\",\n",
    "            \"layer_initializer3\"]\n",
    "            \n",
    "        c = 0\n",
    "        for asdf in zip(*full_parameters):\n",
    "            df[a[c]] = asdf\n",
    "            c +=1\n",
    "        \n",
    "        frames.append(df)\n",
    "#         break\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(\"df.shape:\", df.shape)\n",
    "df.tail()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units1 = []\n",
    "units2 = []\n",
    "units3 = []\n",
    "layer_type1 = []\n",
    "layer_type2 = []\n",
    "layer_type3 = []\n",
    "\n",
    "experiment_directories = [\"18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-2018_16_stations_calendar\",  # BEST O3\n",
    "                          \"18Islands20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "                          \"18Islands5AgentsO3_1994-2018_16_stations_calendar\",\n",
    "                          \"18CellularAutomata3DGrid3x3x3_5AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "                          \"18Islands20AgentsPM10_1994-2018_16_stations_calendar\",  # BEST PM10\n",
    "                          \"18Islands5AgentsPM10_1994-2018_16_stations_calendar\"\n",
    "                         ]\n",
    "\n",
    "# selected_experiments = [experiment_directories[0, 1, 2, 3, 4]]\n",
    "\n",
    "# df_models = df.loc[df[\"experiment\"] == experiment_directories[0]]  # For 1 experiment\n",
    "df_models = df[df['experiment'].isin(experiment_directories[0:1])]\n",
    "# df_models = df[df['experiment'].isin(experiment_directories[4:7])]  # For many experiments\n",
    "df_models = df[df['experiment'].isin(experiment_directories)]  # all experiments\n",
    "first_iterations = 400\n",
    "for element in df_models[\"full_parameters\"].head(first_iterations):  # For the first EA iterations\n",
    "# for element in df_models[\"full_parameters\"]:    \n",
    "    units1.append(element[3])\n",
    "    units2.append(element[4])\n",
    "    units3.append(element[5])\n",
    "    layer_type1.append(np.around(element[21], decimals=0).astype(int))\n",
    "    layer_type2.append(np.around(element[22], decimals=0).astype(int))\n",
    "    layer_type3.append(np.around(element[23], decimals=0).astype(int))\n",
    "#     layer_type1.append(element[15])\n",
    "#     layer_type2.append(element[16])\n",
    "#     layer_type3.append(element[17])\n",
    "units = [units1, units2, units3]    \n",
    "layer_types = [layer_type1, layer_type2, layer_type3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df_model = df_models.loc[df_models[\"holdoutSmapeAccuracy\"] == df_models[\"holdoutSmapeAccuracy\"].max()]\n",
    "best_pm10_params = best_df_model[\"full_parameters\"]\n",
    "layer_types_list = [\"LSTM\", \"BiLSTM\", \"GRU\", \"BiGRU\", \"RNN\", \"BiRNN\"]\n",
    "for element in best_pm10_params:\n",
    "    print(\"\\nBest model(units):\")\n",
    "    print(np.around(element[3], decimals=0).astype(int), end=\", \")\n",
    "    print(np.around(element[4], decimals=0).astype(int), end=\", \")\n",
    "    print(np.around(element[5], decimals=0).astype(int), end=\"\")\n",
    "    print(\"\\nBest model(layers):\")\n",
    "    print(layer_types_list[np.around(element[21], decimals=0).astype(int)], end=\", \")\n",
    "    print(layer_types_list[np.around(element[22], decimals=0).astype(int)], end=\", \")\n",
    "    print(layer_types_list[np.around(element[23], decimals=0).astype(int)], end=\", \")\n",
    "best_df_model\n",
    "list(best_pm10_params)\n",
    "np.around(list(best_pm10_params), decimals=0).astype(int)\n",
    "print(\"\\nMax holdoutSmapeAccuracy: {:.2f}%\".format(df_models[\"holdoutSmapeAccuracy\"].max()))\n",
    "print(\"\\nMin holdoutMse: {:.2f}\".format(df_models[\"holdoutMse\"].min()))\n",
    "print(\"\\nMin cvMseMean: {:.2f}\".format(df_models[\"cvMseMean\"].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_df_model = df_models.loc[df_models[\"holdoutSmapeAccuracy\"] == df_models[\"holdoutSmapeAccuracy\"].min()]\n",
    "worst_pm10_params = worst_df_model[\"full_parameters\"]\n",
    "layer_types_list = [\"LSTM\", \"BiLSTM\", \"GRU\", \"BiGRU\", \"RNN\", \"BiRNN\"]\n",
    "for element in worst_pm10_params:\n",
    "    print(\"\\nBest model(units):\")\n",
    "    print(np.around(element[3], decimals=0).astype(int), end=\", \")\n",
    "    print(np.around(element[4], decimals=0).astype(int), end=\", \")\n",
    "    print(np.around(element[5], decimals=0).astype(int), end=\"\")\n",
    "    print(\"\\nBest model(layers):\")\n",
    "    print(layer_types_list[np.around(element[21], decimals=0).astype(int)], end=\", \")\n",
    "    print(layer_types_list[np.around(element[22], decimals=0).astype(int)], end=\", \")\n",
    "    print(layer_types_list[np.around(element[23], decimals=0).astype(int)], end=\", \")\n",
    "\n",
    "worst_df_model    \n",
    "list(worst_pm10_params)\n",
    "np.around(list(worst_pm10_params), decimals=0).astype(int)\n",
    "print(\"\\nMax holdoutSmapeAccuracy: {:.2f}%\".format(df_models[\"holdoutSmapeAccuracy\"].min()))\n",
    "print(\"\\nMax holdoutMse: {:.2f}\".format(df_models[\"holdoutMse\"].max()))\n",
    "print(\"\\nMax cvMseMean: {:.2f}\".format(df_models[\"cvMseMean\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 14))\n",
    "samples = len(units[0])\n",
    "labels = [\"First Layer\", \"Second Layer\", \"Third Layer\"]\n",
    "all_data = units\n",
    "\n",
    "axes[0].violinplot(all_data, showmeans=False, showmedians=True)\n",
    "axes[0].set_title('Violin plot - RNN (4 layers) layer unit count ({} samples)'.format(samples))\n",
    "axes[1].boxplot(all_data)\n",
    "axes[1].set_title('Box plot - RNN (4 layers) layer unit count ({} samples)'.format(samples))\n",
    "for ax in axes:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xticks([y+1 for y in range(len(all_data))])\n",
    "    ax.set_xlabel('Layers')\n",
    "    ax.set_ylabel('Unit count')\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "         xticklabels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 14))\n",
    "samples = len(layer_types[0])\n",
    "labels = [\"First Layer\", \"Second Layer\", \"Third Layer\"]\n",
    "all_data = layer_types\n",
    "layer_type_labels = ['LSTM', 'LSTM', 'BiLSTM', 'GRU', 'BiGRU', 'SimpleRNN', 'BiSimpleRNN']\n",
    "\n",
    "axes[0].violinplot(all_data, showmeans=False, showmedians=True)\n",
    "axes[0].set_title('Violin plot - RNN (4 layers) layer type ({} samples)'.format(samples))\n",
    "axes[1].boxplot(all_data)\n",
    "axes[1].set_title('Box plot - RNN (4 layers) layer type ({} samples)'.format(samples))\n",
    "for ax in axes:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_xticks([y+1 for y in range(len(all_data))])\n",
    "    ax.set_xlabel('Layers')\n",
    "    ax.set_ylabel('Layer type')\n",
    "plt.setp(axes, xticks=[y+1 for y in range(len(all_data))],\n",
    "         xticklabels=labels, yticklabels=layer_type_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_models\n",
    "first_iterations = 400  # For the first EA iterations\n",
    "# df_models2 = df.loc[df[\"experiment\"] == current_experiment].head(first_iterations)  # For 1 experiment\n",
    "# df_models2 = df[df['experiment'].isin(experiment_directories[4:7])]  # PM10 For many experiments\n",
    "# df_models2 = df[df['experiment'].isin(experiment_directories[0:4])]  # O3\n",
    "df_models2 = df[df['experiment'].isin(experiment_directories)]  # All\n",
    "\n",
    "# df_models2 = df[df['experiment'].isin(experiment_directories[0:4])]  # For many experiments\n",
    "a.append(\"holdoutSmapeAccuracy\")\n",
    "df_models3 = df_models2[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "import seaborn as sns\n",
    "df_models3 = df_models3\n",
    "corrmat = df_models3.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 5 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'holdoutSmapeAccuracy')['holdoutSmapeAccuracy'].index\n",
    "cm = np.corrcoef(df_models3[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "col_labels = cols.values\n",
    "col_labels[0] = \"100 - SMAPE%\"\n",
    "xticklabels = col_labels\n",
    "yticklabels = col_labels\n",
    "\n",
    "# ax.set_title(\"Neuroevolution correlation matrix (best 5): PM10 (4 layer DNN, {} models)\".format((df_models3[cols].shape[0]))\n",
    "ax.set_title(\"DNN (4 layers) correlation matrix: PM10 2018 ({} models)\".format(df_models3.shape[0]))\n",
    "hm = sns.heatmap(cm, ax=ax, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 20}, yticklabels=col_labels, xticklabels=col_labels)\n",
    "hm.set_xticklabels(labels=col_labels, rotation=30)\n",
    "plt.show()\n",
    "fig.savefig(\"pm10correlationMatrix.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 5 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'holdoutSmapeAccuracy')['holdoutSmapeAccuracy'].index\n",
    "cm = np.corrcoef(df_models3[cols].values.T)\n",
    "sns.set(font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "col_labels = cols.values\n",
    "col_labels[0] = \"100 - SMAPE%\"\n",
    "xticklabels = col_labels\n",
    "yticklabels = col_labels\n",
    "\n",
    "# ax.set_title(\"Neuroevolution correlation matrix (best 5): PM10 (4 layer DNN, {} models)\".format((df_models3[cols].shape[0]))\n",
    "# ax.set_title(\"DNN (4 layers) correlation matrix: PM10 2018 ({} models)\".format(df_models3.shape[0]))\n",
    "hm = sns.heatmap(cm, ax=ax, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 20}, yticklabels=col_labels, xticklabels=col_labels)\n",
    "hm.set_xticklabels(labels=col_labels, rotation=25)\n",
    "ax.set_title('Correlation matrix: DNNs with 3 x RNN layers (all {} models)'.format(df_models3.shape[0]))\n",
    "plt.show()\n",
    "fig.savefig(\"dnnCorrelationMatrix.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 5 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'holdoutSmapeAccuracy')['holdoutSmapeAccuracy'].index\n",
    "cm = np.corrcoef(df_models3[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "col_labels = cols.values\n",
    "col_labels[0] = \"100 - SMAPE%\"\n",
    "xticklabels = col_labels\n",
    "yticklabels = col_labels\n",
    "\n",
    "# ax.set_title(\"Neuroevolution correlation matrix (best 5): PM10 (4 layer DNN, {} models)\".format((df_models3[cols].shape[0]))\n",
    "ax.set_title(\"DNN (4 layers) correlation matrix: PM10 2018 ({} models)\".format(df_models3.shape[0]))\n",
    "hm = sns.heatmap(cm, ax=ax, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=col_labels, xticklabels=col_labels)\n",
    "hm.set_xticklabels(labels=col_labels, rotation=30)\n",
    "plt.show()\n",
    "fig.savefig(\"pm10correlationMatrix.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"Blues\")\n",
    "sns.set(font_scale=2.0)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 14))\n",
    "labels = [\"First\", \"Second\", \"Third\"]\n",
    "\n",
    "# ax.boxplot(all_data)\n",
    "# ax.boxplot(df_models3[\"units1\"])\n",
    "# ax.boxplot([df_models3[\"units1\"], df_models3[\"units2\"], df_models3[\"units3\"]])\n",
    "# ax.violinplot([df_models3[\"units1\"], df_models3[\"units2\"], df_models3[\"units3\"]], showmeans=False, showmedians=False)\n",
    "\n",
    "c = \"blue\"\n",
    "\n",
    "# ax.boxplot([df_models3[\"units1\"], df_models3[\"units2\"], df_models3[\"units3\"]], showfliers=True)\n",
    "\n",
    "ax.boxplot([df_models3[\"units1\"], df_models3[\"units2\"], df_models3[\"units3\"]], showfliers=True, notch=False, patch_artist=True,\n",
    "#             boxprops=dict(facecolor=c, color=c),\n",
    "            capprops=dict(color=c),\n",
    "            whiskerprops=dict(color=c),\n",
    "            flierprops=dict(color=c, markeredgecolor=c),\n",
    "            medianprops=dict(color=c))\n",
    "\n",
    "# axes.scatter(all_data)\n",
    "ax.set_title('Layer size: DNNs with 3 x RNN layers (all {} models)'.format(df_models3.shape[0]))\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "ax.set_xticks([y+1 for y in range(len(labels))])\n",
    "ax.set_xlabel('RNN Layers')\n",
    "ax.set_ylabel('Unit count')\n",
    "plt.setp(ax, xticks=[y+1 for y in range(len(labels))], xticklabels=labels)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"layerSizeBoxplot.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(font_scale=2.0)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 14))\n",
    "layer_type_labels = ['LSTM', 'BiLSTM', 'GRU', 'BiGRU', 'SimpleRNN', 'BiSimpleRNN']\n",
    "\n",
    "layer_type_counts = df_models3[\"layer_type3\"].round().astype(int).value_counts()\n",
    "sns.barplot(x=[0, 1, 2, 3, 4, 5], y=layer_type_counts)\n",
    "ax.set_title('Layer types: DNNs with 3 x RNN layers (all {} models)'.format(df_models3.shape[0]))\n",
    "\n",
    "ax.yaxis.grid(True)\n",
    "# ax.set_xticks([y+1 for y in range(len(labels))])\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Layer type')\n",
    "plt.setp(ax, xticklabels=layer_type_labels)\n",
    "plt.show()\n",
    "fig.savefig(\"layerTypeBarplot.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BETN073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.shape: (535, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>island</th>\n",
       "      <th>cvMseMean</th>\n",
       "      <th>cvMseStd</th>\n",
       "      <th>cvSmapeMean</th>\n",
       "      <th>cvSmapeStd</th>\n",
       "      <th>holdoutRmse</th>\n",
       "      <th>holdoutSmape</th>\n",
       "      <th>holdoutMape</th>\n",
       "      <th>holdoutMse</th>\n",
       "      <th>holdoutIoa</th>\n",
       "      <th>full_parameters</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>worker</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1565217864</th>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>177.812315</td>\n",
       "      <td>32.471914</td>\n",
       "      <td>0.172442</td>\n",
       "      <td>0.022697</td>\n",
       "      <td>38.882907</td>\n",
       "      <td>0.333794</td>\n",
       "      <td>0.458735</td>\n",
       "      <td>1511.880452</td>\n",
       "      <td>0.779230</td>\n",
       "      <td>[25.466939139526307, 522.4401645630296, 3.8821...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565219252</th>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>206.700538</td>\n",
       "      <td>52.094948</td>\n",
       "      <td>0.195813</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>63.845649</td>\n",
       "      <td>0.514634</td>\n",
       "      <td>0.830395</td>\n",
       "      <td>4076.266847</td>\n",
       "      <td>0.594632</td>\n",
       "      <td>[25.466939139526307, 522.4401645630296, 3.8821...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565220130</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "      <td>173.499327</td>\n",
       "      <td>28.205400</td>\n",
       "      <td>0.172550</td>\n",
       "      <td>0.022164</td>\n",
       "      <td>43.208769</td>\n",
       "      <td>0.351568</td>\n",
       "      <td>0.492076</td>\n",
       "      <td>1866.997681</td>\n",
       "      <td>0.754220</td>\n",
       "      <td>[25.466939139526307, 522.4401645630296, 3.8821...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565221115</th>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>174.944085</td>\n",
       "      <td>30.118967</td>\n",
       "      <td>0.172345</td>\n",
       "      <td>0.022710</td>\n",
       "      <td>42.892217</td>\n",
       "      <td>0.353532</td>\n",
       "      <td>0.493458</td>\n",
       "      <td>1839.742242</td>\n",
       "      <td>0.756155</td>\n",
       "      <td>[25.466939139526307, 522.4401645630296, 3.8821...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565222004</th>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>174.774018</td>\n",
       "      <td>29.476972</td>\n",
       "      <td>0.173238</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>29.786668</td>\n",
       "      <td>0.268216</td>\n",
       "      <td>0.350665</td>\n",
       "      <td>887.245563</td>\n",
       "      <td>0.845393</td>\n",
       "      <td>[25.466939139526307, 522.4401645630296, 3.8821...</td>\n",
       "      <td>ls</td>\n",
       "      <td>TX2</td>\n",
       "      <td>18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            iteration  island   cvMseMean   cvMseStd  cvSmapeMean  cvSmapeStd  \\\n",
       "datetime                                                                        \n",
       "1565217864         52       3  177.812315  32.471914     0.172442    0.022697   \n",
       "1565219252         53       3  206.700538  52.094948     0.195813    0.046874   \n",
       "1565220130         54       3  173.499327  28.205400     0.172550    0.022164   \n",
       "1565221115         55       3  174.944085  30.118967     0.172345    0.022710   \n",
       "1565222004         56       3  174.774018  29.476972     0.173238    0.024777   \n",
       "\n",
       "            holdoutRmse  holdoutSmape  holdoutMape   holdoutMse  holdoutIoa  \\\n",
       "datetime                                                                      \n",
       "1565217864    38.882907      0.333794     0.458735  1511.880452    0.779230   \n",
       "1565219252    63.845649      0.514634     0.830395  4076.266847    0.594632   \n",
       "1565220130    43.208769      0.351568     0.492076  1866.997681    0.754220   \n",
       "1565221115    42.892217      0.353532     0.493458  1839.742242    0.756155   \n",
       "1565222004    29.786668      0.268216     0.350665   887.245563    0.845393   \n",
       "\n",
       "                                              full_parameters optimizer  \\\n",
       "datetime                                                                  \n",
       "1565217864  [25.466939139526307, 522.4401645630296, 3.8821...        ls   \n",
       "1565219252  [25.466939139526307, 522.4401645630296, 3.8821...        ls   \n",
       "1565220130  [25.466939139526307, 522.4401645630296, 3.8821...        ls   \n",
       "1565221115  [25.466939139526307, 522.4401645630296, 3.8821...        ls   \n",
       "1565222004  [25.466939139526307, 522.4401645630296, 3.8821...        ls   \n",
       "\n",
       "           worker                                         experiment  \n",
       "datetime                                                              \n",
       "1565217864    TX2  18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...  \n",
       "1565219252    TX2  18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...  \n",
       "1565220130    TX2  18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...  \n",
       "1565221115    TX2  18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...  \n",
       "1565222004    TX2  18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "run_directory_prefix = \"../models/NarxModelSearch/runs/\"\n",
    "file_name_pattern = \"*Runs.csv\"\n",
    "columns = [\"datetime\", \"iteration\", \"island\", \"cvMseMean\", \"cvMseStd\", \"cvSmapeMean\", \"cvSmapeStd\", \"holdoutRmse\", \"holdoutSmape\", \"holdoutMape\", \"holdoutMse\", \"holdoutIoa\", \"full_parameters\"]\n",
    "\n",
    "experiment_directories = [\"18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2018_1_station_calendar\"\n",
    "#     \"18CellularAutomata3DGrid3x3x3_5AgentsO3_1994-2018_16_stations_calendar\", \n",
    "#                           \"18CellularAutomata3DGrid3x3x3_20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "#                           \"18Islands20AgentsO3_1994-2018_16_stations_calendar\", \n",
    "#                           \"18Islands5AgentsO3_1994-2018_16_stations_calendar\",\n",
    "#                           \"18CellularAutomata3DGrid3x3x3_5AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "#                           \"18Islands20AgentsPM10_1994-2018_16_stations_calendar\",\n",
    "#                           \"18Islands5AgentsPM10_1994-2018_16_stations_calendar\"\n",
    "                         ]\n",
    "\n",
    "run_directories = []\n",
    "for experiment_directory in experiment_directories:\n",
    "    new_run_directory = run_directory_prefix + experiment_directory + \"/\"\n",
    "#     print(\"new_run_directory:\", new_run_directory)\n",
    "    run_directories.append(new_run_directory)\n",
    "\n",
    "worker_directories = [\"local\", \"TX2\"]\n",
    "\n",
    "# print(run_directories)\n",
    "\n",
    "dirs_list = []\n",
    "for run_directory in run_directories:\n",
    "    dirs_list.append(os.listdir(run_directory))\n",
    "#     print(\"dirs:\", os.listdir(run_directory))\n",
    "    \n",
    "for dirs in dirs_list:\n",
    "    for item in dirs:\n",
    "        if item not in worker_directories:\n",
    "            sub_items = os.listdir(run_directories[0] + item)\n",
    "            for sub_item in sub_items:\n",
    "                sub_path = item +\"/\" + sub_item\n",
    "#                 print(\"sub_path:\", item +\"/\" + sub_item)\n",
    "                worker_directories.append(sub_path)\n",
    "            \n",
    "# print(\"worker_directories:\", worker_directories)\n",
    "\n",
    "paths = []\n",
    "for run_directory in run_directories:\n",
    "    for worker_directory in worker_directories:\n",
    "        experiment = \"\"\n",
    "        if run_directory.startswith(run_directory_prefix):\n",
    "            experiment = run_directory[len(run_directory_prefix):-1]\n",
    "#         print(\"experiment:\", experiment)\n",
    "        paths.append((run_directory + worker_directory + \"/logs/\", worker_directory, experiment))\n",
    "\n",
    "# print(len(paths))\n",
    "    \n",
    "frames = []\n",
    "for path in paths:\n",
    "    for csv_file_path in glob.glob(path[0] + file_name_pattern):\n",
    "#         print(\"csv_file_path:\", csv_file_path)\n",
    "#         print(\"csv_file     :\", csv_file)\n",
    "        df = pd.read_csv(csv_file_path, names=columns, engine=\"python\", index_col=\"datetime\", parse_dates=True)\n",
    "    \n",
    "        if \"EC2\" in path[1]:  # EC2 -> + 1 hour (Ireland)\n",
    "            df.index = df.index + 3600\n",
    "        if \"TX2\" in path[1]:  # TX2 -> + 2 hours (UTC)        \n",
    "            df.index = df.index + 3600 * 2\n",
    "    \n",
    "        df.sort_index(inplace=True)\n",
    "        df[\"optimizer\"] = str(re.search('(.{1,6})Runs.csv', os.path.basename(csv_file_path)).group(1))\n",
    "        df[\"worker\"] = path[1]\n",
    "        df[\"experiment\"] = path[2]\n",
    "#         df[\"cvSmapeMean\"] = 100 * df[\"cvSmapeMean\"]\n",
    "#         df[\"holdoutSmape\"] = 100 * df[\"holdoutSmape\"]  \n",
    "#         df[\"holdoutMape\"] = 100 * df[\"holdoutMape\"]        \n",
    "#         df[\"cvSmapeMeanAccuracy\"] = 100 - df[\"cvSmapeMean\"]\n",
    "#         df[\"holdoutSmapeAccuracy\"] = 100 - df[\"holdoutSmape\"]\n",
    "#         print(\"df.shape\", df.shape)\n",
    "        frames.append(df)\n",
    "#         break\n",
    "\n",
    "df = pd.concat(frames)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "print(\"df.shape:\", df.shape)\n",
    "df.tail()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186.7562634369719"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"holdoutMse\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1376372455258666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"holdoutSmape\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14572651445721616"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"holdoutMape\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9564920468050464"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"holdoutIoa\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5146343739122419"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"holdoutSmape\"].max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
